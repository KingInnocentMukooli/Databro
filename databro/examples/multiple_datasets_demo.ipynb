{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataBro Multi-Dataset Analysis Demo\n",
    "This notebook demonstrates DataBro's capabilities with multiple popular datasets:\n",
    "1. Iris Dataset (Classification)\n",
    "2. Wine Dataset (Classification)\n",
    "3. Breast Cancer Dataset (Binary Classification)\n",
    "4. Diabetes Dataset (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer, load_diabetes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import DataBro components\n",
    "from databro import DataLoader, DataPreprocessor, DataVisualizer, DataSummarizer\n",
    "\n",
    "# Initialize DataBro components\n",
    "loader = DataLoader()\n",
    "preprocessor = DataPreprocessor()\n",
    "visualizer = DataVisualizer()\n",
    "summarizer = DataSummarizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load All Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to convert sklearn dataset to pandas DataFrame\n",
    "def create_dataset(loader_func, name):\n",
    "    data = loader_func()\n",
    "    df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "    df['target'] = data.target\n",
    "    df.to_csv(f'{name}_data.csv', index=False)\n",
    "    return df\n",
    "\n",
    "# Create all datasets\n",
    "iris_df = create_dataset(load_iris, 'iris')\n",
    "wine_df = create_dataset(load_wine, 'wine')\n",
    "cancer_df = create_dataset(load_breast_cancer, 'cancer')\n",
    "diabetes_df = create_dataset(load_diabetes, 'diabetes')\n",
    "\n",
    "datasets = {\n",
    "    'Iris': iris_df,\n",
    "    'Wine': wine_df,\n",
    "    'Breast Cancer': cancer_df,\n",
    "    'Diabetes': diabetes_df\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Display basic information for each dataset\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\n=== {name} Dataset ===\")\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(\"\\nFirst few rows:\")\n",
    "    print(df.head(2))\n",
    "    print(\"\\nFeature names:\")\n",
    "    print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Process each dataset\n",
    "processed_datasets = {}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    print(f\"\\nProcessing {name} dataset...\")\n",
    "    \n",
    "    # Scale features\n",
    "    features = [col for col in df.columns if col != 'target']\n",
    "    scaled_df = preprocessor.scale_data(df, method='standard', columns=features)\n",
    "    \n",
    "    # Store processed dataset\n",
    "    processed_datasets[name] = scaled_df\n",
    "    \n",
    "    print(f\"Shape after processing: {scaled_df.shape}\")\n",
    "    print(\"\\nSample of processed data:\")\n",
    "    print(scaled_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create visualizations for each dataset\n",
    "for name, df in processed_datasets.items():\n",
    "    print(f\"\\n=== Visualizations for {name} Dataset ===\\n\")\n",
    "    \n",
    "    # 1. Correlation Heatmap\n",
    "    print(\"Correlation Heatmap:\")\n",
    "    visualizer.plot_heatmap(df)\n",
    "    \n",
    "    # 2. Distribution of first feature\n",
    "    first_feature = df.columns[0]\n",
    "    print(f\"\\nDistribution of {first_feature}:\")\n",
    "    visualizer.plot_histogram(df, first_feature, interactive=True)\n",
    "    \n",
    "    # 3. Scatter plot of first two features\n",
    "    if len(df.columns) > 2:\n",
    "        print(f\"\\nScatter plot of first two features:\")\n",
    "        visualizer.plot_scatter(df, \n",
    "                               x=df.columns[0], \n",
    "                               y=df.columns[1], \n",
    "                               hue='target',\n",
    "                               interactive=True)\n",
    "    \n",
    "    # 4. Box plot of first feature by target\n",
    "    print(f\"\\nBox plot of {first_feature} by target:\")\n",
    "    visualizer.plot_box(df, column=first_feature, by='target', interactive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Summarization Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate summaries for each dataset\n",
    "for name, df in processed_datasets.items():\n",
    "    print(f\"\\n=== Summary for {name} Dataset ===\\n\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"Basic Statistics:\")\n",
    "    stats = summarizer.get_basic_stats(df)\n",
    "    print(stats)\n",
    "    \n",
    "    # Correlation summary\n",
    "    print(\"\\nStrong Correlations (threshold=0.5):\")\n",
    "    corr_summary = summarizer.get_correlation_summary(df, threshold=0.5)\n",
    "    print(corr_summary)\n",
    "    \n",
    "    # Generate and save full report\n",
    "    report_path = f'{name.lower()}_report.txt'\n",
    "    summarizer.generate_report(df, report_path)\n",
    "    print(f\"\\nFull report saved to: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparative Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Compare dataset characteristics\n",
    "comparison_data = {\n",
    "    'Dataset': [],\n",
    "    'Samples': [],\n",
    "    'Features': [],\n",
    "    'Target Classes': [],\n",
    "    'Missing Values': []\n",
    "}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    comparison_data['Dataset'].append(name)\n",
    "    comparison_data['Samples'].append(len(df))\n",
    "    comparison_data['Features'].append(len(df.columns) - 1)  # Excluding target\n",
    "    comparison_data['Target Classes'].append(len(df['target'].unique()))\n",
    "    comparison_data['Missing Values'].append(df.isnull().sum().sum())\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"Dataset Comparison:\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Processed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save all processed datasets\n",
    "for name, df in processed_datasets.items():\n",
    "    output_path = f'{name.lower()}_processed.csv'\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved processed {name} dataset to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
